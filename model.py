# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19axPyIHejQfywI2xVmZc7o_T9_AgdfUg
"""

import pandas as pd
import random
import pickle
from surprise import Dataset, Reader, SVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ---------- Generate dummy freelancer & interaction data ----------
skill_pool = [
    "Python", "JavaScript", "React", "Angular", "Vue", "Django", "Flask", "FastAPI",
    "TensorFlow", "PyTorch", "Scikit-learn", "Pandas", "NumPy", "OpenCV", "Keras",
    "SQL", "PostgreSQL", "MySQL", "MongoDB", "Firebase", "AWS", "Azure", "GCP",
    "Docker", "Kubernetes", "CI/CD", "Git", "GitHub", "Bitbucket", "Java", "C++",
    "C#", "Go", "Rust", "Ruby", "PHP", "Laravel", "Node.js", "Express.js",
    "NLP", "Computer Vision", "LLMs", "Chatbot", "HuggingFace", "Tableau", "Power BI",
    "Excel", "HTML", "CSS", "SASS", "Redux", "GraphQL", "TypeScript", "Bootstrap",
    "Tailwind", "Figma", "UI/UX"
]

freelancers = [
    {
        "freelancer_id": i,
        "name": f"Freelancer {i}",
        "skills": random.sample(skill_pool, k=random.randint(3, 8)),
        "experience_years": random.randint(1, 15),
        "hourly_rate": random.randint(10, 150),
        "avg_rating": round(random.uniform(3.0, 5.0), 1),
        "jobs_completed": random.randint(5, 200),
        "bio": "Experienced in full-stack development and AI projects."
    }
    for i in range(1, 501)
]
freelancers_df = pd.DataFrame(freelancers)

interactions = pd.DataFrame([
    {
        "client_id": random.randint(100, 120),
        "freelancer_id": random.randint(1, 500),
        "rating": round(random.uniform(3.0, 5.0), 1)
    }
    for _ in range(1000)
])

# ---------- Train collaborative filtering model ----------
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(interactions[["client_id", "freelancer_id", "rating"]], reader)
trainset = data.build_full_trainset()
svd_model = SVD()
svd_model.fit(trainset)

# ---------- Prepare TF-IDF vectorizer and matrix ----------
freelancers_df['skills_str'] = freelancers_df['skills'].apply(lambda x: ' '.join(x))
tfidf = TfidfVectorizer()
freelancer_tfidf = tfidf.fit_transform(freelancers_df['skills_str'])

# ---------- Save everything to model.pkl ----------
model_data = {
    "freelancers_df": freelancers_df,
    "interactions": interactions,
    "svd_model": svd_model,
    "tfidf_vectorizer": tfidf,
    "freelancer_tfidf": freelancer_tfidf
}

with open("model.pkl", "wb") as f:
    pickle.dump(model_data, f)

print("âœ… model.pkl generated and saved successfully.")

# pip install scikit-surprise

# !pip install numpy==1.24.4

